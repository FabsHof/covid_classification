{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe2c629",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Pre-Processing\n",
    "\n",
    "> See [README-file](../README.md) for more information on how to set up the project.\n",
    "\n",
    "This notebook includes steps that prepare the dataset for training and evaluation, including restructuring of the dataset and applying masks to the input images.\n",
    "\n",
    "## Dataset Structure\n",
    "\n",
    "The original dataset is structured in a way that is not optimal for training machine learning models. The updated structure includes separate folders for training, validation, and testing, as well as subfolders for images, masks, as well as the masked images. The rate of train/val/test split is `72/18/10` (classes being stratified).\n",
    "\n",
    "```\n",
    "# Original structure\n",
    "- data/\n",
    "    - COVID/\n",
    "        - images/\n",
    "        - masks/\n",
    "    - ...\n",
    "\n",
    "# New structure\n",
    "- data_split/\n",
    "    - images/\n",
    "        - train/\n",
    "            - COVID/\n",
    "            - Lung_Opacity/\n",
    "            - Normal/\n",
    "            - Viral Pneumonia/\n",
    "        - val/\n",
    "            - ...\n",
    "        - test/\n",
    "            - ...\n",
    "    - masks/\n",
    "        - train/\n",
    "            - ...\n",
    "        - val/\n",
    "            - ...\n",
    "        - test/\n",
    "            - ...\n",
    "    - masked_images/\n",
    "        - train/\n",
    "            - ...\n",
    "        - val/\n",
    "            - ...\n",
    "        - test/\n",
    "            - ...\n",
    "```\n",
    "\n",
    "## Processing Steps\n",
    "\n",
    "1. **Environment Detection**: Automatically detect whether we're running in Google Colab or local environment\n",
    "2. **Dataset Restructuring**: Split the original dataset into train/validation/test sets with stratified sampling\n",
    "3. **Mask Application**: Apply masks to create focused images for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57a065bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting pre-processing setup...\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload modules before executing code.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from os import path\n",
    "\n",
    "# Add src directory to path for imports\n",
    "sys.path.append(path.join(\"..\", \"src\"))\n",
    "\n",
    "from src.util.environment import setup_environment, get_dataset_config\n",
    "from src.util.dataset import restructure_dataset\n",
    "from src.util.image_processing import create_masked_images\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s - %(message)s\")\n",
    "\n",
    "print(\"üöÄ Starting pre-processing setup...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03ca7ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Not running in Google Colab.\n",
      "INFO - Environment setup complete. Running in local environment\n",
      "INFO - Paths: {'data_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data', 'split_data_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split', 'models_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/models', 'image_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split/images', 'test_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split/images/test'}\n",
      "INFO - Environment setup complete. Running in local environment\n",
      "INFO - Paths: {'data_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data', 'split_data_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split', 'models_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/models', 'image_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split/images', 'test_path': '/Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split/images/test'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detecting environment and setting up paths...\n",
      "üìç Environment: Local\n",
      "üìÇ Data path: /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data\n",
      "üìÇ Split data path: /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split\n",
      "üè∑Ô∏è  Dataset classes: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
      "üìä Split ratio: (0.72, 0.18, 0.1)\n",
      "‚úÖ Source data directory found\n"
     ]
    }
   ],
   "source": [
    "# üåç Environment Detection and Setup\n",
    "print(\"üîç Detecting environment and setting up paths...\")\n",
    "\n",
    "# Setup environment (detects Colab vs local, mounts drive if needed, loads config)\n",
    "is_google_colab, config, paths = setup_environment()\n",
    "\n",
    "# Get dataset configuration\n",
    "dataset_config = get_dataset_config()\n",
    "\n",
    "print(f\"üìç Environment: {'Google Colab' if is_google_colab else 'Local'}\")\n",
    "print(f\"üìÇ Data path: {paths['data_path']}\")\n",
    "print(f\"üìÇ Split data path: {paths['split_data_path']}\")\n",
    "print(f\"üè∑Ô∏è  Dataset classes: {dataset_config['classes']}\")\n",
    "print(f\"üìä Split ratio: {dataset_config['split_ratio']}\")\n",
    "\n",
    "# Check if source data exists\n",
    "import os\n",
    "\n",
    "if os.path.exists(paths[\"data_path\"]):\n",
    "    print(f\"‚úÖ Source data directory found\")\n",
    "else:\n",
    "    print(f\"‚ùå Source data directory not found: {paths['data_path']}\")\n",
    "    print(\n",
    "        \"Please ensure the dataset is downloaded and placed in the correct\"\n",
    "        \" location.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f23bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - > Restructuring dataset from /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data to /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split with split ratio (0.72, 0.18, 0.1).\n",
      "INFO - \t- Removing existing target directory: /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split\n",
      "INFO - \t- Removing existing target directory: /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting dataset restructuring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - \t- Class COVID: 2603 train, 650 val, 363 test files\n",
      "INFO - \t- Class Lung_Opacity: 4328 train, 1082 val, 602 test files\n",
      "INFO - \t- Class Lung_Opacity: 4328 train, 1082 val, 602 test files\n",
      "INFO - \t- Class Normal: 7338 train, 1834 val, 1020 test files\n",
      "INFO - \t- Class Normal: 7338 train, 1834 val, 1020 test files\n",
      "INFO - \t- Class Viral Pneumonia: 968 train, 242 val, 135 test files\n",
      "INFO - \t- Class Viral Pneumonia: 968 train, 242 val, 135 test files\n",
      "INFO - \t- Dataset restructuring completed. Files copied to /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split.\n",
      "INFO - \t- Dataset restructuring completed. Files copied to /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset restructuring completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# üîÑ Dataset Restructuring\n",
    "print(\"üîÑ Starting dataset restructuring...\")\n",
    "\n",
    "try:\n",
    "    restructure_dataset(\n",
    "        source_dir=paths[\"data_path\"],\n",
    "        target_dir=paths[\"split_data_path\"],\n",
    "        dataset_classes=dataset_config[\"classes\"],\n",
    "        dataset_categories=dataset_config[\"categories\"],\n",
    "        split_ratio=dataset_config[\"split_ratio\"],\n",
    "        random_seed=dataset_config[\"random_seed\"],\n",
    "    )\n",
    "    print(\"‚úÖ Dataset restructuring completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during dataset restructuring: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6530fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Creating masked images in /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Creating masked images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Processed 2603 images for class COVID, split train\n",
      "INFO - Processed 4328 images for class Lung_Opacity, split train\n",
      "INFO - Processed 4328 images for class Lung_Opacity, split train\n",
      "INFO - Processed 7338 images for class Normal, split train\n",
      "INFO - Processed 7338 images for class Normal, split train\n",
      "INFO - Processed 968 images for class Viral Pneumonia, split train\n",
      "INFO - Processed 968 images for class Viral Pneumonia, split train\n",
      "INFO - Processed 650 images for class COVID, split val\n",
      "INFO - Processed 650 images for class COVID, split val\n",
      "INFO - Processed 1082 images for class Lung_Opacity, split val\n",
      "INFO - Processed 1082 images for class Lung_Opacity, split val\n",
      "INFO - Processed 1834 images for class Normal, split val\n",
      "INFO - Processed 1834 images for class Normal, split val\n",
      "INFO - Processed 242 images for class Viral Pneumonia, split val\n",
      "INFO - Processed 242 images for class Viral Pneumonia, split val\n",
      "INFO - Processed 363 images for class COVID, split test\n",
      "INFO - Processed 363 images for class COVID, split test\n",
      "INFO - Processed 602 images for class Lung_Opacity, split test\n",
      "INFO - Processed 602 images for class Lung_Opacity, split test\n",
      "INFO - Processed 1020 images for class Normal, split test\n",
      "INFO - Processed 1020 images for class Normal, split test\n",
      "INFO - Processed 135 images for class Viral Pneumonia, split test\n",
      "INFO - Masked images creation completed\n",
      "INFO - Processed 135 images for class Viral Pneumonia, split test\n",
      "INFO - Masked images creation completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Masked images creation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# üé≠ Creating Masked Images\n",
    "print(\"üé≠ Creating masked images...\")\n",
    "\n",
    "try:\n",
    "    create_masked_images(\n",
    "        split_data_path=paths[\"split_data_path\"],\n",
    "        dataset_classes=dataset_config[\"classes\"],\n",
    "    )\n",
    "    print(\"‚úÖ Masked images creation completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during masked images creation: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bdf3e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Generating dataset summary...\n",
      "\n",
      "üìà Dataset Statistics:\n",
      "============================================================\n",
      "\n",
      "IMAGES:\n",
      "------------------------------\n",
      "Train: 15237 files\n",
      "  - COVID: 2603\n",
      "  - Lung_Opacity: 4328\n",
      "  - Normal: 7338\n",
      "  - Viral Pneumonia: 968\n",
      "Val: 3808 files\n",
      "  - COVID: 650\n",
      "  - Lung_Opacity: 1082\n",
      "  - Normal: 1834\n",
      "  - Viral Pneumonia: 242\n",
      "Test: 2120 files\n",
      "  - COVID: 363\n",
      "  - Lung_Opacity: 602\n",
      "  - Normal: 1020\n",
      "  - Viral Pneumonia: 135\n",
      "\n",
      "MASKS:\n",
      "------------------------------\n",
      "Train: 15237 files\n",
      "  - COVID: 2603\n",
      "  - Lung_Opacity: 4328\n",
      "  - Normal: 7338\n",
      "  - Viral Pneumonia: 968\n",
      "Val: 3808 files\n",
      "  - COVID: 650\n",
      "  - Lung_Opacity: 1082\n",
      "  - Normal: 1834\n",
      "  - Viral Pneumonia: 242\n",
      "Test: 2120 files\n",
      "  - COVID: 363\n",
      "  - Lung_Opacity: 602\n",
      "  - Normal: 1020\n",
      "  - Viral Pneumonia: 135\n",
      "\n",
      "MASKED_IMAGES:\n",
      "------------------------------\n",
      "Train: 15237 files\n",
      "  - COVID: 2603\n",
      "  - Lung_Opacity: 4328\n",
      "  - Normal: 7338\n",
      "  - Viral Pneumonia: 968\n",
      "Val: 3808 files\n",
      "  - COVID: 650\n",
      "  - Lung_Opacity: 1082\n",
      "  - Normal: 1834\n",
      "  - Viral Pneumonia: 242\n",
      "Test: 2120 files\n",
      "  - COVID: 363\n",
      "  - Lung_Opacity: 602\n",
      "  - Normal: 1020\n",
      "  - Viral Pneumonia: 135\n",
      "\n",
      "‚úÖ Pre-processing pipeline completed successfully!\n",
      "üìÇ Processed dataset available at: /Users/fabianhofmann/‚å®Ô∏è_development/git_projects/covid_classification/data_split\n"
     ]
    }
   ],
   "source": [
    "# üìä Dataset Summary and Verification\n",
    "print(\"üìä Generating dataset summary...\")\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    \"\"\"Count files in a directory structure.\"\"\"\n",
    "    counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory {directory} does not exist\")\n",
    "        return counts\n",
    "\n",
    "    for category in [\"images\", \"masks\", \"masked_images\"]:\n",
    "        category_path = os.path.join(directory, category)\n",
    "        if os.path.exists(category_path):\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                split_path = os.path.join(category_path, split)\n",
    "                if os.path.exists(split_path):\n",
    "                    for cls in dataset_config[\"classes\"]:\n",
    "                        cls_path = os.path.join(split_path, cls)\n",
    "                        if os.path.exists(cls_path):\n",
    "                            file_count = len([\n",
    "                                f\n",
    "                                for f in os.listdir(cls_path)\n",
    "                                if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "                            ])\n",
    "                            counts[category][split][cls] = file_count\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "# Count files in the processed dataset\n",
    "if os.path.exists(paths[\"split_data_path\"]):\n",
    "    counts = count_files_in_directory(paths[\"split_data_path\"])\n",
    "\n",
    "    print(\"\\nüìà Dataset Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for category in [\"images\", \"masks\", \"masked_images\"]:\n",
    "        if category in counts:\n",
    "            print(f\"\\n{category.upper()}:\")\n",
    "            print(\"-\" * 30)\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                if split in counts[category]:\n",
    "                    total = sum(counts[category][split].values())\n",
    "                    print(f\"{split.capitalize()}: {total} files\")\n",
    "                    for cls in dataset_config[\"classes\"]:\n",
    "                        count = counts[category][split].get(cls, 0)\n",
    "                        print(f\"  - {cls}: {count}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Pre-processing pipeline completed successfully!\")\n",
    "    print(f\"üìÇ Processed dataset available at: {paths['split_data_path']}\")\n",
    "else:\n",
    "    print(f\"‚ùå Split data directory not found: {paths['split_data_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
